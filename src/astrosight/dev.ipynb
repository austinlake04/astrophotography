{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from typing import Optional\n",
    "import glob\n",
    "import git\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rawpy\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from PySide6.QtCore import Slot, QObject, QSize\n",
    "from PySide6.QtQuick import QQuickImageProvider\n",
    "from PySide6.QtGui import QGuiApplication, QImage, QPixmap, QColor\n",
    "from PySide6.QtWidgets import QFileDialog\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import ipywidgets as widgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtCore import Qt, QAbstractItemModel, QModelIndex\n",
    "\n",
    "class TreeModel(QAbstractItemModel):\n",
    "    def __init__(self, headers, data, parent=None):\n",
    "        super(TreeModel, self).__init__(parent)\n",
    "        rootData = [header for header in headers]\n",
    "        self.rootItem = TreeNode(rootData)\n",
    "        indent = -1\n",
    "        self.parents = [self.rootItem]\n",
    "        self.indentations = [0]\n",
    "        self.createData(data, indent)\n",
    "\n",
    "    def createData(self, data, indent):\n",
    "        if type(data) == dict:\n",
    "            indent += 1\n",
    "            position = 4 * indent\n",
    "            for dict_keys, dict_values in data.items():\n",
    "                if position > self.indentations[-1]:\n",
    "                    if self.parents[-1].childCount() > 0:\n",
    "                        self.parents.append(self.parents[-1].child(self.parents[-1].childCount() - 1))\n",
    "                        self.indentations.append(position)\n",
    "                else:\n",
    "                    while position < self.indentations[-1] and len(self.parents) > 0:\n",
    "                        self.parents.pop()\n",
    "                        self.indentations.pop()\n",
    "                parent = self.parents[-1]\n",
    "                parent.insertChildren(parent.childCount(), 1, parent.columnCount())\n",
    "                parent.child(parent.childCount() - 1).setData(0, dict_keys)\n",
    "                if type(dict_values) != dict:\n",
    "                    parent.child(parent.childCount() - 1).setData(1, str(dict_values))\n",
    "                self.createData(dict_values, indent)\n",
    "\n",
    "    def index(self, row, column, index=QModelIndex()):\n",
    "        if not self.hasIndex(row, column, index):\n",
    "            return QModelIndex()\n",
    "        if not index.isValid():\n",
    "            item = self.rootItem\n",
    "        else:\n",
    "            item = index.internalPointer()\n",
    "        child = item.child(row)\n",
    "        if child:\n",
    "            return self.createIndex(row, column, child)\n",
    "        return QModelIndex()\n",
    "\n",
    "    def parent(self, index):\n",
    "        if not index.isValid():\n",
    "            return QModelIndex()\n",
    "        item = index.internalPointer()\n",
    "        if not item:\n",
    "            return QModelIndex()\n",
    "        parent = item.parentItem\n",
    "        if parent == self.rootItem:\n",
    "            return QModelIndex()\n",
    "        else:\n",
    "            return self.createIndex(parent.childNumber(), 0, parent)\n",
    "\n",
    "    def rowCount(self, index=QModelIndex()):\n",
    "        if index.isValid():\n",
    "            parent = index.internalPointer()\n",
    "        else:\n",
    "            parent = self.rootItem\n",
    "        return parent.childCount()\n",
    "\n",
    "    def columnCount(self, index=QModelIndex()):\n",
    "        return self.rootItem.columnCount()\n",
    "\n",
    "    def data(self, index, role=Qt.DisplayRole):\n",
    "        if index.isValid() and role == Qt.DisplayRole:\n",
    "            return index.internalPointer().data(index.column())\n",
    "        elif not index.isValid():\n",
    "            return self.rootItem.data(index.column())\n",
    "\n",
    "    def headerData(self, section, orientation, role=Qt.DisplayRole):\n",
    "        if orientation == Qt.Horizontal and role == Qt.DisplayRole:\n",
    "            return self.rootItem.data(section)\n",
    "\n",
    "class TreeNode(object):\n",
    "    def __init__(self, data, parent=None):\n",
    "        self.parentItem = parent\n",
    "        self.itemData = data\n",
    "        self.children = []\n",
    "\n",
    "    def child(self, row):\n",
    "        return self.children[row]\n",
    "\n",
    "    def childCount(self):\n",
    "        return len(self.children)\n",
    "\n",
    "    def childNumber(self):\n",
    "        if self.parentItem is not None:\n",
    "            return self.parentItem.children.index(self)\n",
    "\n",
    "    def columnCount(self):\n",
    "        return len(self.itemData)\n",
    "\n",
    "    def data(self, column):\n",
    "        return self.itemData[column]\n",
    "\n",
    "    def insertChildren(self, position, count, columns):\n",
    "        if position < 0 or position > len(self.children):\n",
    "            return False\n",
    "        for row in range(count):\n",
    "            data = [None for v in range(columns)]\n",
    "            item = TreeNode(data, self)\n",
    "            self.children.insert(position, item)\n",
    "\n",
    "    def parent(self):\n",
    "        return self.parentItem\n",
    "\n",
    "    def setData(self, column, value):\n",
    "        if column < 0 or column >= len(self.itemData):\n",
    "            return False\n",
    "        self.itemData[column] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(\n",
    "    image: np.ndarray, \n",
    "    dtype: type\n",
    ") -> np.ndarray:\n",
    "    if np.iinfo(image.dtype).max < np.iinfo(dtype).max:\n",
    "        return image.astype(dtype)\n",
    "    return ((image - np.iinfo(image.dtype).min/np.iinfo(image.dtype).max) * np.iinfo(dtype).max).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestImage(self, id: str, size: QSize, requestedSize: QSize) -> QImage:\n",
    "    files = glob.glob(\"M31Andromeda/*.FITS\")\n",
    "    assert len(files) > int(id)\n",
    "    file = os.path.abspath(files[int(id)])\n",
    "    print(file)\n",
    "    assert os.path.isfile(file), \"RAW file doesn't exist.\"\n",
    "    if file[-5:] in [\".fits\", \".FITS\"] or \\\n",
    "        file[-4:] in [\".fit\", \".FIT\"]:\n",
    "        raw_image = fits.getdata(file, ext=0)\n",
    "    elif file[-5:] in [\".tiff\", \".jpeg\"] or \\\n",
    "        file[-4:] in [\".tif\", \".tif\", \".png\"]:\n",
    "        raw_image = imageio.imread(file)\n",
    "    else:\n",
    "        try:\n",
    "            with rawpy.imread(file) as raw:\n",
    "                raw_image = raw.raw_image\n",
    "        except rawpy.LibRawError:\n",
    "            print(\"Invalid file format.\")\n",
    "            return None\n",
    "    #raw_image = self.resample(raw_image, dtype=np.uint16)\n",
    "    print(raw_image.shape)\n",
    "    print(raw_image.dtype)\n",
    "    h, w = raw_image.shape[:2]\n",
    "    bytes_per_line = w * \\\n",
    "        (2 if raw_image.dtype == np.uint16 else 1) * \\\n",
    "        (raw_image.shape[2] if len(raw_image.shape) > 2 else 1)\n",
    "    fmt = QImage.Format_Grayscale16 if raw_image.dtype == np.uint16 else QImage.Format_Grayscale8\n",
    "    return QImage(raw_image.data, w, h, bytes_per_line, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Detector(Enum):\n",
    "    ORB = cv2.ORB_create()\n",
    "    SIFT = cv2.SIFT_create()\n",
    "    AKAZE = cv2.AKAZE_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(\n",
    "    demosaic_algorithm=None,\n",
    "    half_size=False,\n",
    "    four_color_rgb=False,\n",
    "    dcb_iterations=0,\n",
    "    dcb_enhance=False,\n",
    "    fbdd_noise_reduction=rawpy.FBDDNoiseReductionMode.Off,\n",
    "    noise_thr=None,\n",
    "    median_filter_passes=0,\n",
    "    use_camera_wb=False,\n",
    "    use_auto_wb=False,\n",
    "    user_wb=None,\n",
    "    output_color=rawpy.ColorSpace.sRGB,\n",
    "    output_bps=8,\n",
    "    user_flip=None,\n",
    "    user_black=None,\n",
    "    user_sat=None,\n",
    "    no_auto_bright=False,\n",
    "    auto_bright_thr=None,\n",
    "    adjust_maximum_thr=0.75,\n",
    "    bright=1.0,\n",
    "    highlight_mode=rawpy.HighlightMode.Clip,\n",
    "    exp_shift=None,\n",
    "    exp_preserve_highlights=0.0,\n",
    "    no_auto_scale=False,\n",
    "    gamma=None,\n",
    "    chromatic_aberration=None,\n",
    "    bad_pixels_path=None\n",
    ") -> None:\n",
    "    postprocess_params = rawpy.Params(\n",
    "        demosaic_algorithm=None,\n",
    "        half_size=False,\n",
    "        four_color_rgb=False,\n",
    "        dcb_iterations=0,\n",
    "        dcb_enhance=False,\n",
    "        fbdd_noise_reduction=rawpy.FBDDNoiseReductionMode.Off,\n",
    "        noise_thr=None,\n",
    "        median_filter_passes=0,\n",
    "        use_camera_wb=False,\n",
    "        use_auto_wb=False,\n",
    "        user_wb=None,\n",
    "        output_color=rawpy.ColorSpace.sRGB,\n",
    "        output_bps=8,\n",
    "        user_flip=None,\n",
    "        user_black=None,\n",
    "        user_sat=None,\n",
    "        no_auto_bright=False,\n",
    "        auto_bright_thr=None,\n",
    "        adjust_maximum_thr=0.75,\n",
    "        bright=1.0,\n",
    "        highlight_mode=rawpy.HighlightMode.Clip,\n",
    "        exp_shift=None,\n",
    "        exp_preserve_highlights=0.0,\n",
    "        no_auto_scale=False,\n",
    "        gamma=None,\n",
    "        chromatic_aberration=None,\n",
    "        bad_pixels_path=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(\n",
    "    image: np.ndarray,\n",
    "    master_dark: Optional[np.ndarray] = None,\n",
    "    master_flat: Optional[np.ndarray] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calibrates an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        Uncalibrated image.\n",
    "    master_dark : numpy.ndarray\n",
    "        Master dark calibration frame.\n",
    "    master_flat : numpy.ndarray\n",
    "        Master flat calibration frame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image : numpy.ndarray\n",
    "        Calibrated image\n",
    "    \"\"\"\n",
    "    image = 1.0 * image  # floating point conversion for data retention in computation\n",
    "    if master_dark is not None:\n",
    "        image = image - master_dark\n",
    "    if master_flat is not None:\n",
    "        image = image / master_flat\n",
    "    image[image < 0] = 0\n",
    "    image = image.astype(np.uint16)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(\n",
    "    raw_file: str,\n",
    "    params: rawpy.Params\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"Loads and processes an astrophotography image at a specified file path.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    raw_file : str\n",
    "        Path to specified RAW file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image : Optional[numpy.ndarray]\n",
    "        Unprocessed raw image\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if raw_file[-5::] == \".fits\" or raw_file[-4::] == \".fts\":\n",
    "            with fits.open(raw_file) as hdul:\n",
    "                image = hdul[0].data\n",
    "        else:\n",
    "            with rawpy.imread(raw_file) as raw:\n",
    "                image = raw.postprocess(params)\n",
    "    except rawpy.LibRawError:\n",
    "        return None\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(\n",
    "    raw_file: str\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Loads preview of RAW image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_file : str\n",
    "        Path to RAW file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    raw_image : numpy.ndarray\n",
    "        Data for RAW image\n",
    "    \"\"\"\n",
    "    raw_image = load(raw_file)\n",
    "    if raw_image:\n",
    "        w, h, c = raw_image.shape\n",
    "        raw_image = QImage(raw_image, w, h, 3*w, QImage.Format.Format_RGB888)\n",
    "        return raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_calibration(\n",
    "    file_tree: dict[list[str]],\n",
    ") -> tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "    \"\"\"Generates calibration frame from a specified image set.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    file_tree : dict[list[str]]\n",
    "        File tree containing light, dark, bias, and flat images.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    master_dark : Optional[numpy.ndarray]\n",
    "        Master dark calibration frame\n",
    "    master_flat : Optional[numpy.ndarray]\n",
    "        Master flat calibration frame\n",
    "    \"\"\"\n",
    "    \n",
    "    bias_frames = np.array(list(map(load, file_tree[\"Bias\"])))\n",
    "    master_bias = np.mean(bias_frames, axis=0) if len(bias_frames) else None\n",
    "\n",
    "    dark_frames = np.array(list(map(load, file_tree[\"Dark\"])))\n",
    "    master_dark = np.mean(dark_frames, axis=0) if len(dark_frames) else None\n",
    "\n",
    "    dark_flat_frames = np.array(list(map(load, file_tree[\"Dark Flat\"])))\n",
    "    master_dark_flat = np.mean(dark_flat_frames, axis=0) if len(dark_flat_frames) else None\n",
    "    if master_dark_flat:\n",
    "        if master_bias is not None:\n",
    "            master_dark_flat -= master_bias\n",
    "\n",
    "    flat_frames = np.array(list(map(load, file_tree[\"Flat\"])))\n",
    "    master_flat = np.mean(flat_frames, axis=0) if len(flat_frames) else None\n",
    "    if master_flat:\n",
    "        if master_bias is not None:\n",
    "            master_flat -= master_bias\n",
    "        if master_dark_flat is not None:\n",
    "            master_flat -= master_dark_flat\n",
    "\n",
    "    return master_dark, master_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(\n",
    "    image: np.ndarray, \n",
    "    detector: Detector\n",
    ") -> tuple[Optional[tuple[cv2.KeyPoint]], Optional[np.ndarray]]: \n",
    "    scale = False\n",
    "    if scale:\n",
    "        if np.max(image) < 255:\n",
    "            image = 257 * image\n",
    "        peaks, _ = find_peaks(image.flatten(), height=7 * 257)\n",
    "        row, col = divmod(peaks, image.shape[0])\n",
    "        save = image[row, col]\n",
    "        image = image.astype(np.uint16)\n",
    "        image[row, col] = np.iinfo(np.uint16).max\n",
    "    keypoints, descriptors = detector.value.detectAndCompute(resample(image, dtype=np.uint8), None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register(\n",
    "    image: np.ndarray,\n",
    "    base_keypoints: tuple[cv2.KeyPoint],\n",
    "    base_descriptors: np.ndarray,\n",
    "    detector: Detector,\n",
    "    match_threshhold: float = 0.8,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Registers and aligns an image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        Calibrated image\n",
    "    features : tuple[tuple[cv2.KeyPoint], numpy.ndarray]\n",
    "        Keypoints and descriptors from features of interest for current image.\n",
    "    base_features : tuple[tuple[cv2.KeyPoint], numpy.ndarray]\n",
    "        Keypoints and descriptors for features of interest of reference image.\n",
    "    feature_detector : str\n",
    "        Feature detector (ORB, SIFT, or AKAZE) to indentify prominent stars.\n",
    "    match_threshhold : float\n",
    "        Percentage of matches to include in registration process.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image : numpy.ndarray\n",
    "        Calibrated and registered image.\n",
    "    \"\"\"\n",
    "    keypoints, descriptors = detect_features(image, detector)\n",
    "\n",
    "    matcher = (\n",
    "        cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        if detector == Detector.SIFT\n",
    "        else cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    )\n",
    "    matches = matcher.match(descriptors, base_descriptors, None)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    if detector == Detector.SIFT:\n",
    "        matches = [m1 for m1, m2 in matches if m1.distance < 0.6 * m2.distance]\n",
    "    else:\n",
    "        matches = matches[: int(len(matches) * match_threshhold)]\n",
    "\n",
    "    features = [keypoints, base_keypoints]\n",
    "    points = np.empty((2, len(matches), 2))\n",
    "    for i, feature in enumerate(features):\n",
    "        for j, match in enumerate(matches):\n",
    "            points[i, j, :] = feature[match.trainIdx if i else match.queryIdx].pt\n",
    "    try:\n",
    "        homography, mask = cv2.findHomography(points[0], points[1], cv2.RANSAC)\n",
    "        image = cv2.warpPerspective(image, homography, (image.shape[1], image.shape[0]))\n",
    "    except cv2.error:\n",
    "        dx = int(base_keypoints[0].pt[0] - keypoints[0].pt[0])\n",
    "        dy = int(base_keypoints[0].pt[1] - keypoints[0].pt[1])\n",
    "        image = np.roll(image, dx, axis=1)\n",
    "        image = np.roll(image, dy, axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(\n",
    "    image: np.ndarray,\n",
    "    filename: Optional[str] = None,\n",
    "    save: bool = False\n",
    ") -> None:\n",
    "    \"\"\"Displays an image.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    image : numpy.ndarray\n",
    "        Image to be displayed.\n",
    "    filename : Optional[str]\n",
    "        Filename in which to save resulting image.\n",
    "    save : bool\n",
    "        Determines if resulting image is automatically saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    filename = filename.replace(\"_\", \" \") if filename else \"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(resample(image, dtype=np.uint8), cmap=(None if len(image.shape) == 3 else \"gray\"))\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.title(filename)\n",
    "    plt.axis(\"off\")\n",
    "    if save:\n",
    "        plt.savefig(filename, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(\n",
    "    file_tree: dict[list[str]],\n",
    "    detector: Detector,\n",
    "    params: rawpy.Params,\n",
    "    reference_index: int = 0,\n",
    "    filename: Optional[str] = None,\n",
    "    save: bool = False,\n",
    "    verbose: bool = True\n",
    ") -> None:\n",
    "    \"\"\"Stacks astrophotography images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_tree : dict[list[str]]\n",
    "        Absolute paths to light, bias, dark, dark flat, and flat images.\n",
    "    detector : str\n",
    "        Feature detector (ORB, SIFT, or AKAZE) to indentify prominent stars.\n",
    "    filename : Optional[str]\n",
    "        Filename in which to save resulting image.\n",
    "    save : bool\n",
    "        Determines if resulting image is automatically saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stacked_image: numpy.ndarray\n",
    "        Stacked image\n",
    "    \"\"\"\n",
    "    load_with_params = lambda file: load(file, params) \n",
    "    \n",
    "    bias_frames = np.array(list(map(load_with_params, file_tree[\"Bias\"])))\n",
    "    master_bias = np.mean(bias_frames, axis=0) if len(bias_frames) else None\n",
    "    if verbose and master_bias is not None:\n",
    "        print(\"loaded bias frames\")\n",
    "\n",
    "    dark_frames = np.array(list(map(load_with_params, file_tree[\"Dark\"])))\n",
    "    master_dark = np.mean(dark_frames, axis=0) if len(dark_frames) else None\n",
    "    if verbose and master_dark is not None:\n",
    "        print(\"loaded dark frames\")\n",
    "\n",
    "    dark_flat_frames = np.array(list(map(load_with_params, file_tree[\"Dark Flat\"])))\n",
    "    master_dark_flat = np.mean(dark_flat_frames, axis=0) if len(dark_flat_frames) else None\n",
    "    if master_dark_flat:\n",
    "        if master_bias is not None:\n",
    "            master_dark_flat -= master_bias\n",
    "    if verbose and master_dark_flat is not None:\n",
    "        print(\"loaded dark flat frames\")\n",
    "\n",
    "    flat_frames = np.array(list(map(load_with_params, file_tree[\"Flat\"])))\n",
    "    master_flat = np.mean(flat_frames, axis=0) if len(flat_frames) else None\n",
    "    if master_flat:\n",
    "        if master_bias is not None:\n",
    "            master_flat -= master_bias\n",
    "        if master_dark_flat is not None:\n",
    "            master_flat -= master_dark_flat,\n",
    "    if verbose and master_flat is not None:\n",
    "        print(\"loaded flat frames\")\n",
    "\n",
    "    light_frames = np.array(list(map(load_with_params, file_tree[\"Light\"])))\n",
    "    light_frames = np.array(list(map(lambda frame: calibrate(frame, master_dark, master_flat), light_frames)))\n",
    "    if verbose:\n",
    "        print(\"loaded light frames\")\n",
    "\n",
    "    base_keypoints, base_descriptors = detect_features(light_frames[reference_index], detector) \n",
    "    light_frames = np.array(list(map(\n",
    "        lambda index: light_frames[index] if index == reference_index else register(light_frames[index], base_keypoints, base_descriptors, detector),\n",
    "        range(len(light_frames))\n",
    "    )))\n",
    "    if verbose:\n",
    "        print(\"registered light frames\")\n",
    "\n",
    "    stacked_image = np.sum(light_frames, axis=0)\n",
    "    display(stacked_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8f3badbc124ea680e821128c216120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='demosaic_algorithm', max=12), Dropdown(description='half…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@widgets.interact(\n",
    "    demosaic_algorithm=(0,12),\n",
    "    half_size=[True,False],\n",
    "    four_color_rgb=[True,False],\n",
    "    dcb_iterations=(0,10),\n",
    "    dcb_enhance=[True,False],\n",
    "    fbdd_noise_reduction=(0,2),\n",
    "    noise_thr=(0.0,1.0),\n",
    "    median_filter_passes=(0,10),\n",
    "    use_camera_wb=[True,False],\n",
    "    use_auto_wb=[True,False],\n",
    "    r_wb=(0.0,1.0),\n",
    "    g1_wb=(0.0,1.0),\n",
    "    g2_wb=(0.0,1.0),\n",
    "    b_wb=(0.0,1.0),\n",
    "    output_color=(0,8),\n",
    "    output_bps=[8,16],\n",
    "    user_flip=[0,3,5,6],\n",
    "    user_black=(0,255),\n",
    "    user_sat=(0,255),\n",
    "    no_auto_scale=[True,False],\n",
    "    no_auto_bright=[True,False],\n",
    "    auto_bright_thr=(0.0,1.0),\n",
    "    adjust_maximum_thr=(0.0,1.0),\n",
    "    bright=(0.0,1.0),\n",
    "    highlight_mode=(0,2),\n",
    "    exp_shift=(0.25,8.0),\n",
    "    exp_preserve_highlights=(0.0,1.0),\n",
    "    power=(0.0,5.0),\n",
    "    slope=(0.0,5.0),\n",
    "    red_scale=(0,1),\n",
    "    blue_scale=(0,1),\n",
    "    bad_pixels_path=[None]   \n",
    ")\n",
    "def choose_params(\n",
    "    demosaic_algorithm: int = 3,\n",
    "    half_size: bool = False,\n",
    "    four_color_rgb: bool = False,\n",
    "    dcb_iterations: int = 0,\n",
    "    dcb_enhance: bool = False,\n",
    "    fbdd_noise_reduction: int = 0,\n",
    "    noise_thr: float = None,\n",
    "    median_filter_passes: int = 0,\n",
    "    use_camera_wb: bool = True,\n",
    "    use_auto_wb: bool = False,\n",
    "    r_wb: float = 1.0,\n",
    "    g1_wb: float = 1.0,\n",
    "    g2_wb: float = 1.0,\n",
    "    b_wb: float = 1.0,\n",
    "    output_color: int = 1,\n",
    "    output_bps: int = 16,\n",
    "    user_flip: int = 0,\n",
    "    user_black: int = None,\n",
    "    user_sat: int = None,\n",
    "    no_auto_scale: bool = False,\n",
    "    no_auto_bright: bool = False,\n",
    "    auto_bright_thr: float = None,\n",
    "    adjust_maximum_thr: float = 0.75,\n",
    "    bright: float = 1.0,\n",
    "    highlight_mode: int = 1,\n",
    "    exp_shift: float = 1.0,\n",
    "    exp_preserve_highlights: float = 0.0,\n",
    "    power: float = 2.222,\n",
    "    slope: float = 4.5,\n",
    "    red_scale: int = 1,\n",
    "    blue_scale: int = 1,\n",
    "    bad_pixels_path: str = None\n",
    "):\n",
    "    params = rawpy.Params(\n",
    "        demosaic_algorithm=rawpy.DemosaicAlgorithm(demosaic_algorithm),\n",
    "        half_size=half_size,\n",
    "        four_color_rgb=four_color_rgb,\n",
    "        dcb_iterations=dcb_iterations,\n",
    "        dcb_enhance=dcb_enhance,\n",
    "        fbdd_noise_reduction=rawpy.FBDDNoiseReductionMode(fbdd_noise_reduction),\n",
    "        noise_thr=noise_thr,\n",
    "        median_filter_passes=median_filter_passes,\n",
    "        use_camera_wb=use_camera_wb,\n",
    "        use_auto_wb=use_auto_wb,\n",
    "        user_wb=[r_wb,g1_wb,g2_wb,b_wb],\n",
    "        output_color=rawpy.ColorSpace(output_color),\n",
    "        output_bps=output_bps,\n",
    "        user_flip=user_flip,\n",
    "        user_black=user_black,\n",
    "        user_sat=user_sat,\n",
    "        no_auto_scale=no_auto_scale,\n",
    "        no_auto_bright=no_auto_bright,\n",
    "        auto_bright_thr=auto_bright_thr,\n",
    "        adjust_maximum_thr=adjust_maximum_thr,\n",
    "        bright=bright,\n",
    "        highlight_mode=rawpy.HighlightMode(highlight_mode),\n",
    "        exp_shift=exp_shift,\n",
    "        exp_preserve_highlights=exp_preserve_highlights,\n",
    "        gamma=(power,slope),\n",
    "        chromatic_aberration=(red_scale,blue_scale),\n",
    "        bad_pixels_path=bad_pixels_path\n",
    "    )\n",
    "\n",
    "    repo = git.Repo('.', search_parent_directories=True)\n",
    "    image_catagories = [\"Light\", \"Bias\", \"Dark\", \"Dark Flat\", \"Flat\"]\n",
    "    file_tree = {}\n",
    "    for catagory in image_catagories:\n",
    "        file_tree[catagory] = glob.glob(f\"{repo.working_tree_dir}/src/test_data/{catagory}/*.ARW\")\n",
    "    #print(type(Detector.SIFT))\n",
    "    stack(file_tree, Detector.ORB, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
